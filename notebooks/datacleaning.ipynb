{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitanaconda3virtualenv9b7bc183029240479f6be3eb0b77fa3c",
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/lesropro/the_dive/DATAthon/poller_opposites_election_hackathon/ignorefiles/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tweet(tweet) -> str:\n",
    "  ''' \n",
    "  Takes a string, removes punctuation, non-ascii, and stems remaining text\n",
    "  input:\n",
    "    str tweet: a string representing a tweet's text\n",
    "  output:\n",
    "    str tweet: a stemmed tweet with no punctuation or non-ascii characters\n",
    "  '''\n",
    "  tweet = tweet.translate(str.maketrans('','',string.punctuation))\n",
    "  tweet = str(tweet.encode(\"ascii\",\"ignore\"))[2:-1]\n",
    "  stemmer = EnglishStemmer()\n",
    "  tokens = word_tokenize(tweet)\n",
    "  tweet = ''\n",
    "  for token in tokens:\n",
    "    tweet = tweet+stemmer.stem(token)+\" \"\n",
    "  return tweet[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(df):\n",
    "    '''\n",
    "    Takes in dataframe with of user column and creates new columns with subset of information within the column.\n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['clean_text'] = df['full_text'].apply(prepare_tweet)\n",
    "    df['description'] = df['user'].apply(lambda X: X[X.find(\"'description': \")+16:X.find(\", 'url':\")-1])\n",
    "    df['location'] = df['user'].apply(lambda X: X[X.find(\"'location': \")+13:X.find(\", 'description': \")-1])\n",
    "    df['language'] = df['user'].apply(lambda X: X[X.find(\"'lang': \")+9:X.find(\", 'contributors_enabled': \")-1])\n",
    "    df['followers'] = df['user'].apply(lambda X: X[X.find(\"'followers_count': \")+19:X.find(\", 'friends_count': \")-1])\n",
    "    df['friends'] = df['user'].apply(lambda X: X[X.find(\"'friends_count': \")+18:X.find(\", 'listed_count': \")-1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device(x):\n",
    "    '''\n",
    "    Identifies the type of device used to send the tweet.\n",
    "    input:\n",
    "        string: \n",
    "    output:\n",
    "        string:\n",
    "    '''\n",
    "\n",
    "    devices = ['iPhone','iPad','Android','Web App', 'Media Studio', 'Echofon','TweetDeck', 'viriya', 'Twibble.io', 'dlvr.it', 'Tweetbot','TwitPanePlus','SocialFlow', 'News Aggregator', 'Instagram', 'Bot', 'bot', 'iphone','android','web app','News','news']\n",
    "\n",
    "    for dev in devices:\n",
    "        if dev in str(x):\n",
    "            return dev\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_device_column(df):\n",
    "    '''\n",
    "    Converts the created_at column into datetime and creates new columns for time-series analysis.\n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['device'] = df['source'].apply(device)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(df):\n",
    "    '''\n",
    "    Converts the created_at column into datetime and creates new columns for time-series analysis.\n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['hour'] = df.created_at.apply(lambda x: x.hour)\n",
    "    df['date'] = df.created_at.apply(lambda x: x.date)\n",
    "    df['month'] = df.created_at.apply(lambda x: x.month)\n",
    "    df['dayofweek'] = df.created_at.apply(lambda x: x.dayofweek)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_long = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "\n",
    "state_abbv = ['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_clean(x):\n",
    "\n",
    "    if x == 'United States':\n",
    "        return 'USA'\n",
    "    elif x == 'USA':\n",
    "        return 'USA'\n",
    "    elif x == 'America':\n",
    "        return 'USA'\n",
    "    elif x == 'United States of America':\n",
    "        return 'USA'\n",
    "    elif x == ' USA':\n",
    "        return 'USA'\n",
    "    elif x == 'U.S.A.':\n",
    "        return 'USA'\n",
    "    elif x == 'Los Angeles':\n",
    "        return 'CA'\n",
    "    elif x == 'Boston':\n",
    "        return 'MA'\n",
    "    elif x == 'Chicago':\n",
    "        return 'IL'\n",
    "    elif x == 'Seattle':\n",
    "        return 'WA'\n",
    "    elif x == 'USA ':\n",
    "        return 'USA'\n",
    "    elif x == 'UNITED STATES':\n",
    "        return 'USA'\n",
    "    else:\n",
    "        for sl, sa in zip(state_long, state_abbv):\n",
    "            if sl in x or sa in x:\n",
    "                return sa\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_location(df):\n",
    "    '''\n",
    "    creates a new column for locations by states and corrects for edge cases.\n",
    "    \n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['clean_loc'] = df['location'].apply(location_clean)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_tweets(df):\n",
    "    '''\n",
    "    creates a new column with cleaned up tweets and combines the description of the user to the tweet.\n",
    "    \n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['clean_description'] = df['description'].apply(prepare_tweet)\n",
    "    df['combined_text'] = df['clean_text'] + df['clean_description']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_df(df, save_as ,ext):\n",
    "    '''\n",
    "    saves final dataframe into specified file extension.\n",
    "    \n",
    "    input:\n",
    "        pandas dataframe, pandas save method (to_json, to_csv, etc.)\n",
    "        \n",
    "    '''\n",
    "    df.save_as('final_df.{ext}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}