{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitanaconda3virtualenv9b7bc183029240479f6be3eb0b77fa3c",
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import porter\n",
    "from nltk.stem.util import suffix_replace, prefix_replace\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import SnowballStemmer\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/lesropro/the_dive/DATAthon/poller_opposites_election_hackathon/ignorefiles/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tweet(tweet) -> str:\n",
    "  ''' \n",
    "  Takes a string, removes punctuation, non-ascii, and stems remaining text\n",
    "  input:\n",
    "    str tweet: a string representing a tweet's text\n",
    "  output:\n",
    "    str tweet: a stemmed tweet with no punctuation or non-ascii characters\n",
    "  '''\n",
    "  tweet = tweet.translate(str.maketrans('','',string.punctuation))\n",
    "  tweet = str(tweet.encode(\"ascii\",\"ignore\"))[2:-1]\n",
    "  stemmer = EnglishStemmer()\n",
    "  tokens = word_tokenize(tweet)\n",
    "  tweet = ''\n",
    "  for token in tokens:\n",
    "    tweet = tweet+stemmer.stem(token)+\" \"\n",
    "  return tweet[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_invalid_rows(df):\n",
    "    df.drop(axis=0, labels=[110181,110182], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(df):\n",
    "    '''\n",
    "    Takes in dataframe with of user column and creates new columns with subset of information within the column.\n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['clean_text'] = df['full_text'].apply(prepare_tweet)\n",
    "    df['description'] = df['user'].apply(lambda X: X[X.find(\"'description': \")+16:X.find(\", 'url':\")-1])\n",
    "    df['location'] = df['user'].apply(lambda X: X[X.find(\"'location': \")+13:X.find(\", 'description': \")-1])\n",
    "    df['language'] = df['user'].apply(lambda X: X[X.find(\"'lang': \")+9:X.find(\", 'contributors_enabled': \")-1])\n",
    "    df['followers'] = df['user'].apply(lambda X: X[X.find(\"'followers_count': \")+19:X.find(\", 'friends_count': \")-1])\n",
    "    df['friends'] = df['user'].apply(lambda X: X[X.find(\"'friends_count': \")+18:X.find(\", 'listed_count': \")-1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device(x):\n",
    "    '''\n",
    "    Identifies the type of device used to send the tweet.\n",
    "    input:\n",
    "        string: \n",
    "    output:\n",
    "        string:\n",
    "    '''\n",
    "\n",
    "    devices = ['iPhone','iPad','Android','Web App', 'Media Studio', 'Echofon','TweetDeck', 'viriya', 'Twibble.io', 'dlvr.it', 'Tweetbot','TwitPanePlus','SocialFlow', 'News Aggregator', 'Instagram', 'Bot', 'bot', 'iphone','android','web app','News','news']\n",
    "\n",
    "    for dev in devices:\n",
    "        if dev in str(x):\n",
    "            return dev\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_device_column(df):\n",
    "    '''\n",
    "    Converts the created_at column into datetime and creates new columns for time-series analysis.\n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['device'] = df['source'].apply(device)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(df):\n",
    "    '''\n",
    "    Converts the created_at column into datetime and creates new columns for time-series analysis.\n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['hour'] = df.created_at.apply(lambda x: x.hour)\n",
    "    df['date'] = df.created_at.apply(lambda x: x.date)\n",
    "    df['month'] = df.created_at.apply(lambda x: x.month)\n",
    "    df['dayofweek'] = df.created_at.apply(lambda x: x.dayofweek)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_long = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "\n",
    "state_abbv = ['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_clean(x):\n",
    "\n",
    "    if x == 'United States':\n",
    "        return 'USA'\n",
    "    elif x == 'USA':\n",
    "        return 'USA'\n",
    "    elif x == 'America':\n",
    "        return 'USA'\n",
    "    elif x == 'United States of America':\n",
    "        return 'USA'\n",
    "    elif x == ' USA':\n",
    "        return 'USA'\n",
    "    elif x == 'U.S.A.':\n",
    "        return 'USA'\n",
    "    elif x == 'Los Angeles':\n",
    "        return 'CA'\n",
    "    elif x == 'Boston':\n",
    "        return 'MA'\n",
    "    elif x == 'Chicago':\n",
    "        return 'IL'\n",
    "    elif x == 'Seattle':\n",
    "        return 'WA'\n",
    "    elif x == 'USA ':\n",
    "        return 'USA'\n",
    "    elif x == 'UNITED STATES':\n",
    "        return 'USA'\n",
    "    else:\n",
    "        for sl, sa in zip(state_long, state_abbv):\n",
    "            if sl in x or sa in x:\n",
    "                return sa\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_location(df):\n",
    "    '''\n",
    "    creates a new column for locations by states and corrects for edge cases.\n",
    "    \n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['clean_loc'] = df['location'].apply(location_clean)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_tweets(df):\n",
    "    '''\n",
    "    creates a new column with cleaned up tweets and combines the description of the user to the tweet.\n",
    "    \n",
    "    input:\n",
    "        pandas dataframe: \n",
    "    output:\n",
    "        dataframe with new columns \n",
    "    '''\n",
    "    df['clean_description'] = df['description'].apply(prepare_tweet)\n",
    "    df['combined_text'] = df['clean_text'] + df['clean_description']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_df(df, save_as ,ext):\n",
    "    '''\n",
    "    saves final dataframe into specified file extension.\n",
    "    \n",
    "    input:\n",
    "        pandas dataframe, pandas save method (to_json, to_csv, etc.)\n",
    "        \n",
    "    '''\n",
    "    df.save_as('final_df.{ext}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_invalid_rows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 140336 entries, 0 to 140337\nData columns (total 34 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   Unnamed: 0                 140336 non-null  object \n 1   created_at                 140336 non-null  object \n 2   id                         140336 non-null  object \n 3   id_str                     140336 non-null  object \n 4   full_text                  140336 non-null  object \n 5   truncated                  140336 non-null  object \n 6   display_text_range         140336 non-null  object \n 7   entities                   140336 non-null  object \n 8   source                     140318 non-null  object \n 9   in_reply_to_status_id      19111 non-null   object \n 10  in_reply_to_status_id_str  19111 non-null   object \n 11  in_reply_to_user_id        20180 non-null   float64\n 12  in_reply_to_user_id_str    20180 non-null   float64\n 13  in_reply_to_screen_name    20178 non-null   object \n 14  user                       140336 non-null  object \n 15  geo                        2 non-null       object \n 16  coordinates                2 non-null       object \n 17  place                      778 non-null     object \n 18  contributors               0 non-null       float64\n 19  is_quote_status            140336 non-null  object \n 20  quoted_status_id           24453 non-null   float64\n 21  quoted_status_id_str       24453 non-null   float64\n 22  quoted_status_permalink    24452 non-null   object \n 23  quoted_status              7572 non-null    object \n 24  retweet_count              140336 non-null  float64\n 25  favorite_count             140336 non-null  object \n 26  favorited                  140336 non-null  object \n 27  retweeted                  140336 non-null  object \n 28  possibly_sensitive         32332 non-null   float64\n 29  lang                       140336 non-null  object \n 30  retweeted_status           106900 non-null  object \n 31  extended_entities          14627 non-null   object \n 32  withheld_in_countries      36 non-null      object \n 33  clean_text                 140336 non-null  object \ndtypes: float64(7), object(27)\nmemory usage: 37.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}